{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865b1079-f123-425c-a83d-875aff9feb8a",
   "metadata": {},
   "source": [
    "# Easy ways to improve the search relevancy\n",
    "\n",
    "Up till now, we have tested various embedding models, but it doesn't mean we have covered all the possible ways to make sure our search results are relevant. Relevance is sometimes not about the document itself, but about some additional criteria, such as geographical proximity, recency, or some other business rules that none of the models can capture. They may also vary over time, so it's clear we cannot encode them directly in the vectors. Qdrant has some mechanisms that can boost the quality of the retrieval outputs with little effort, so no vector computations are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2223b80a-a97c-4a0e-b50d-6af8dc7605bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b87ea47-ac5e-4831-83f4-ec29eaf0740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See: https://qdrant.github.io/fastembed/examples/Supported_Models/#supported-text-embedding-models\n",
    "COLLECTION_NAME = \"hackernews-hybrid-rag\"\n",
    "\n",
    "# Dense retrieval\n",
    "MODEL_NAME = \"BAAI/bge-small-en-v1.5\"\n",
    "VECTOR_SIZE = 384\n",
    "VECTOR_NAME = \"bge-small-en-v1.5\"\n",
    "\n",
    "# Sparse model\n",
    "BM25_MODEL_NAME = \"Qdrant/bm25\"\n",
    "BM25_VECTOR_NAME = \"bm25\"\n",
    "\n",
    "# Token-level representations\n",
    "MUTLIVECTOR_MODEL_NAME = \"colbert-ir/colbertv2.0\"\n",
    "MULTIVECTOR_SIZE = 128\n",
    "MULTIVECTOR_NAME = \"colbertv2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a16948-54ae-4772-a4e0-eef7e7c19af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "import os\n",
    "\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51e3942-a344-4003-b2d4-fdd77138a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from any_llm import acompletion\n",
    "from typing import Callable\n",
    "\n",
    "RetieverFunc = Callable[[str, int], list[str]]\n",
    "\n",
    "\n",
    "async def rag(q: str, retrieve_func: RetieverFunc, *, n_docs: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Run single-turn RAG on a given input query.\n",
    "    Return just the model response.\n",
    "    \"\"\"\n",
    "    docs = retrieve_func(q, n_docs)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Please provide a response to my question based only \" +\n",
    "                \"on the provided context and only it. If it doesn't \" +\n",
    "                \"contain any helpful information, please let me know \" +\n",
    "                \"and admit you cannot produce relevant answer.\\n\" +\n",
    "                f\"<context>{'\\n'.join(docs)}</context>\\n\" +\n",
    "                f\"<question>{q}</question>\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    response = await acompletion(\n",
    "        provider=os.environ.get(\"LLM_PROVIDER\"),\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce63321-5bb5-41f0-be6a-a4166fc2d538",
   "metadata": {},
   "source": [
    "## Search diversity\n",
    "\n",
    "Your Retrieval Augmented Generation might be only as good as the retrieved documents provided to the LLM. A common issue in RAG-like applications is a lack of diversity in the retrieved documents and passing dozens of near duplicates. If a document does not bring any additional information, then we're only wasting tokens. It makes sense to diversify the set of results to cover a broader spectrum. Unfortunately, vector search alone will always return the documents with the highest scores possible, and that's what it is expected to do. Search results diversification is typically achieved as a post-processing step, and for that, we need to retrieve more candidates and choose a subset that maximizes the diversity. Qdrant has implemented a Maximal Marginal Relevance algorithm that does exactly this. It's also part of the Universal Query API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71297e4-220b-46cd-9dd7-d0398068bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_diverse(q: str, n_docs: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the provided query\n",
    "    with BM25 and dense retrieval + MMR to diversify\n",
    "    on ColBERT vectors.\n",
    "    \"\"\"\n",
    "    result = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=BM25_MODEL_NAME,\n",
    "                ),\n",
    "                using=BM25_VECTOR_NAME,\n",
    "                # Ten times more than expected\n",
    "                limit=(n_docs * 10),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=MODEL_NAME,\n",
    "                ),\n",
    "                using=VECTOR_NAME,\n",
    "                # Ten times more than expected\n",
    "                limit=(n_docs * 10),\n",
    "            ),\n",
    "        ],\n",
    "        # Maximal Marginal Relevance\n",
    "        query=models.NearestQuery(\n",
    "            nearest=models.Document(\n",
    "                text=q,\n",
    "                model=MUTLIVECTOR_MODEL_NAME,\n",
    "            ),\n",
    "            mmr=models.Mmr(\n",
    "                # 0.0 - relevance only, 1.0 - diversity only\n",
    "                diversity=0.75,\n",
    "            )\n",
    "        ),\n",
    "        using=MULTIVECTOR_NAME,\n",
    "        limit=n_docs,\n",
    "    )\n",
    "    docs = [\n",
    "        f\"{point.payload['datetime']} {point.payload['title']} {point.payload['text']}\"\n",
    "        for point in result.points\n",
    "    ]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42adf477-4243-41de-b008-420d2ba4b97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-11-21T19:20:29Z Show HN: Neum AI – Open-source large-scale RAG framework Over the last couple months we have been supporting developers in building large-scale RAG pipelines to process millions of pieces of data.<p>We documented our approach in an HN post (<a href=\"https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37824547\">https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37824547</a>) a couple weeks ago. Today, we are open sourcing the framework we have developed.<p>The framework focuses on RAG data pipelines and provides scale, reliability, and data synchronization capabilities out of the box.<p>For those newer to RAG, it is a technique to provide context to Large Language Models. It consists of grabbing pieces of information (i.e. pieces of news articles, papers, descriptions, etc.) and incorporating them into prompts to help contextualize the responses. The technique goes one level deeper in finding the right pieces of information to incorporate. The search for relevant information is done through the use of vector embeddings and vector databases.<p>Those pieces of news articles, papers, etc. are transformed into a vector embedding that represents the semantic meaning of the information. These vector representations are organized into indexes where we can quickly search for the pieces of information that most closely resembles (from a semantic perspective) a given question or query. For example, if I take news articles from this year, vectorize them, and add them to an index, I can quickly search for pieces of information about the US elections.<p>To help achieve this, the Neum AI framework features:<p>Starting with built-in data connectors for common data sources, embedding services and vector stores, the framework provides modularity to build data pipelines to your specification.<p>The connectors support pre-processing capabilities to define loading, chunking and selecting strategies to optimize content to be embedded. This also includes extracting metadata that is going to be associated to a given vector.<p>The generated pipelines support large scale jobs through a high throughput distributed architecture. The connectors allow you to parallelize tasks like downloading documents, processing them, generating embedding and ingesting data into the vector DB.<p>For data sources that might be continuously changing, the framework supports data scheduling and synchronization. This includes delta syncs where only new data is pulled.<p>Once data is transformed into a vector database, the framework supports querying of the data including hybrid search using the available metadata added during pre-processing. As part of the querying process, the framework provides capabilities to capture feedback on retrieved data as well as run evaluations against different pipeline configurations.<p>Try it out and if interested in chatting more about this shoot us an email founders@tryneum.com',\n",
       " '2024-01-30T01:21:03Z Ask HN: How would you architect a scraper system? I’m looking into how large scale scraping systems work. I’m building https:&#x2F;&#x2F;cardog.io was interested in the “best practices” for strict formatted scraping systems. I’m thinking of using kafka handle the scraped data intake and transformation. Does anyone have any experience building something like this?',\n",
       " '2024-03-07T23:28:03Z Ask HN: What do you use for interactive visualization of large data sets? Any data scientists here that communicate their results or data sets through interactive plots? I was wondering what your favorite tool or package would be for this task.\\nWorking mainly in python, I often find myself using plotly or bokeh but find both packages&#x27; syntax clunky and unintuitive. Moreover, none of these scale well to large data sets - most of these solutions can not handle a simple 2d scatter plot with over 10k points. Commercial tools like Tableau are an option, but at the cost of some flexibility.',\n",
       " '2024-01-25T20:27:44Z Show HN: ChatGPT for Your Data I built an ai agent that can connect to your database.\\nThere&#x27;s a lot of text-to-sql ai tools out there, here are the 2 key differences about my approach:\\n1. AI Agent - I give the Agent a bunch of tools and let it decide what tools to call, in what order, with which parameters, in order to help the user. this means you can ask super vague questions and the agent helps you think through coming up with a good answer.\\n2. Metadata graph &amp; embeddings - I use an LLM to create metadata about the db schemas including things like join keys, column descriptions, and table contents. I also convert this metadata into embeddings. this powers a kNN search that the agent can use to find the right data in the db.<p>if you would be willing to give it a try please put in your email on the page. thanks!',\n",
       " '2024-01-09T19:28:18Z Show HN: Run ETL Pipelines and Store Data in GitHub Hey HN! We built an extension to GitHub that scales repos to handle large files.<p>One of the side effects of this is that you can use GitHub actions to run data ETL pipelines and store the results in the same repo as your ETL code. No need to manage S3 credentials or setup a bunch of extra tools for many ETL jobs.<p>I wrote a quick tutorial on how that works here:<p>https:&#x2F;&#x2F;about.xethub.com&#x2F;blog&#x2F;simple-etl-pipelines-git-xet-github-actions<p>This is our starter repo if you want to try this yourself:<p>https:&#x2F;&#x2F;github.com&#x2F;xetdata&#x2F;easy-etl-template',\n",
       " '2023-10-16T13:48:39Z Show HN: Search on Site: Your One-Tap Specific Site Search Tool Discover a seamless and intuitive way to search within a specific website using &quot;Search On Site&quot; Chrome Extension! Forget the hassle of navigating through numerous pages to find what you need. With Search On Site, a streamlined site-specific search is at your fingertips.<p>Here&#x27;s how you do it:<p>1. Jump to the navigation bar with a simple (Ctrl+L).\\n2. Type in the keyword &quot;son&quot; and hit the TAB or Space.\\n3. Voila! Start typing your query and get directed to the precise information you seek on the specified site.<p>But wait, there&#x27;s more! With our added context menu search functionality, right-clicking any highlighted text on a webpage will instantly enable a search on the targeted site. It’s searching made simple, swift, and smart!<p>Whether for research, shopping, or just quenching your curiosity, Search On Site is your go-to extension for a hassle-free and focused search experience. Add Search On Site to your Chrome browser today and redefine how you search on your favorite websites!',\n",
       " '2024-06-25T12:42:01Z Show HN: Semantweet Search SemanTweet Search allows you to do embedding search over all your tweets from the Twitter archive.<p>It preprocesses your tweets, generates embeddings using OpenAI&#x27;s small&#x2F;large embedding model, stores the data and embeddings in LanceDB vector db, and provides a web interface to search and view the results.<p>You can do semantic search post pre-filtering by time, likes, retweets, media only or link only tweets too.<p>Pre-filtering by sql operations helps not only filter but also reduce the vector search space thus speeding up the search.<p>It also supports semantic search over images with help of open-clip embedding.<p>Background: Twitter&#x27;s search does not work well especially for older tweets. Sometimes, I don&#x27;t know the exact keywords to search so I built an embedding search over tweets.<p>I also post a lot of memes and images so I added an option for creating a image search engine - you can search by text or image. The results will lead you back to the original tweet.',\n",
       " '2023-10-24T17:31:50Z Ask HN: Does there exist a read-optimized distributed K-V store? I have a large-ish (right now ~billions of keys, ~100TB) immutable&#x2F;append-only dataset, with rare inserts (~1GB chunks, once every few minutes) done only by background bulk insert, and no need for any kind of consistency (i.e. inserted data isn&#x27;t &quot;from&quot; users, and so nobody is expecting inserted data to be reflected immediately; and keys inserted together don&#x27;t even need to become visible atomically, as clients will retry to fetch dependent keys.)<p>And I need to serve huge numbers (~trillions) of single-key point queries out of this dataset, out to many consumers over the Internet, with each fetch having as little per-fetch read latency as possible — ideally, with round-trip times resembling e.g. a Redis GET.<p>Basically, I want the performance properties that you&#x27;d get in a single-node scenario from using LMDB and dedicating all your RAM to OS disk cache — but &quot;in the large&quot;, with data being sharded into vnodes and then those vnodes being spread+replicated across an elastically auto-scaled set of compute replicas.<p>You&#x27;d think the answer would be a thing that calls itself something like a &quot;distributed KV store&quot;, &quot;serverless NoSQL store&quot;, etc.<p>But it seems that all the big &quot;distributed KV store&quot; products and services — DynamoDB, BigTable, Cassandra, Riak KV, FoundationDB, CockroachDB, ScyllaDB, etc. — are all built to optimize for <i>write</i> throughput in a many-distributed-writers use-case, with little concern for per-read latency. They&#x27;re all &quot;LevelDB in the large&quot;, not &quot;LMDB in the large.&quot;<p>Does HN know of any system that <i>would</i> suit my use-case? Or, if not, any ideas why nobody has built one?',\n",
       " '2024-01-21T15:06:40Z Show HN: Search on S3 Using AWS Lambda Hi everyone,<p>During the last 3 months, I worked on the Quickwit search engine to adapt it for AWS Lambda runtime. I wrote a blog post to announce the beta release [0] and two tutorials to quickstart:<p>- Indexing and searching 20 million logs entries dataset [1].<p>- Implementing an E2E use case where an application generates data, uploads it in batches to S3. Users can then search through an HTTP API authenticated with an API Key [2].<p>On the performance side, I observed on a 20 million log dataset that search is sub-second, and analytics queries take from 1 to 4 second.<p>On the cost side, obviously the compute using Lambda is fairly expensive, but the huge win is that it scales to 0. Few other solutions do. For instance OpenSearch Serverless has a fixed cost around $700&#x2F;months. On the search side, thanks to indexing, queries are usually way cheaper than scanning services like CloudWatch (at least 50x cheaper).<p>I would love to get the feedback from the community and see how I can push this further.<p>[0]: Blog post <a href=\"https:&#x2F;&#x2F;quickwit.io&#x2F;blog&#x2F;quickwit-lambda-beta\" rel=\"nofollow\">https:&#x2F;&#x2F;quickwit.io&#x2F;blog&#x2F;quickwit-lambda-beta</a><p>[1]: 20 million log dataset search tutorial <a href=\"https:&#x2F;&#x2F;quickwit.io&#x2F;docs&#x2F;get-started&#x2F;tutorials&#x2F;tutorial-aws-lambda-simple\" rel=\"nofollow\">https:&#x2F;&#x2F;quickwit.io&#x2F;docs&#x2F;get-started&#x2F;tutorials&#x2F;tutorial-aws-...</a><p>[2]: E2E use case tutorial <a href=\"https:&#x2F;&#x2F;quickwit.io&#x2F;docs&#x2F;guides&#x2F;e2e-serverless-aws-lambda\" rel=\"nofollow\">https:&#x2F;&#x2F;quickwit.io&#x2F;docs&#x2F;guides&#x2F;e2e-serverless-aws-lambda</a>',\n",
       " '2024-03-20T19:23:11Z Show HN: GritQL, a Rust CLI for rewriting source code Hi everyone!<p>I’m excited to open source GritQL, a Rust CLI for searching and transforming source code.<p>GritQL comes from my experiences with conducting large scale refactors and migrations.<p>Usually, I would start exploring a codebase with grep. This is easy to start with, but most migrations end up accumulating additional requirements like ensuring the right packages are imported and excluding cases which don’t have a viable migration path.<p>Eventually, to build a complex migration, I usually ended up having to write a full codemod program with a tool like jscodeshift. This comes with its own problems:<p>- Most of the exploratory work has to be abandoned as you figure out how to represent your original regex search as an AST.\\n- Reading&#x2F;writing a codemod requires mentally translating from AST names back to what source code actually looks like.\\n- Performance is often an afterthought, so iterating on a large codemod can be painfully slow.\\n- Codemod frameworks are language-specific, so if you’re hopping between multiple languages—or trying to migrate a shared API—you have to learn different tools.<p>GritQL is an attempt to develop a powerful middle ground:\\n- Exploratory analysis is easy: just put a code snippet in backticks and use $metavariables for placeholders.\\n- Incrementally add complexity by introducing side conditions with where clauses.\\n- Reuse named patterns to avoid rebuilding queries, and use shared patterns from our standard library for common tasks like ensuring modules are imported.\\n- Iterate on large codebases quickly: we use Rust for maximum performance<p>GritQL has already been used on thousands of repositories for complex migrations[1] but we&#x27;re excited to collaborate more with the open source community.<p>[1] Ex. <a href=\"https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-python&#x2F;discussions&#x2F;742\">https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;openai-python&#x2F;discussions&#x2F;742</a>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_diverse(\"How do I perform a KNN search on a large scale?\", n_docs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d42ed3-453b-4d8c-9bd8-869b9d0f2d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/16/25 11:20:53] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> max_tokens is required for Anthropic, setting to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>                     <a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/16/25 11:20:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m max_tokens is required for Anthropic, setting to \u001b[1;36m8192\u001b[0m                     \u001b]8;id=813180;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=456384;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\u001b\\\u001b[2m279\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can find some relevant information about performing KNN search on a large scale:\n",
      "\n",
      "From the Neum AI RAG framework post, there are a few approaches mentioned for large-scale KNN search:\n",
      "\n",
      "1. **Vector Embeddings and Vector Databases**: The context explains that pieces of information are \"transformed into a vector embedding that represents the semantic meaning of the information. These vector representations are organized into indexes where we can quickly search for the pieces of information that most closely resembles (from a semantic perspective) a given question or query.\"\n",
      "\n",
      "2. **High Throughput Distributed Architecture**: The Neum AI framework mentions supporting \"large scale jobs through a high throughput distributed architecture\" where you can \"parallelize tasks like downloading documents, processing them, generating embedding and ingesting data into the vector DB.\"\n",
      "\n",
      "3. **Metadata-Enhanced Search**: The framework supports \"hybrid search using the available metadata added during pre-processing\" and provides \"capabilities to capture feedback on retrieved data as well as run evaluations against different pipeline configurations.\"\n",
      "\n",
      "4. **Pre-filtering to Reduce Search Space**: From the SemanTweet Search example, it mentions that \"pre-filtering by sql operations helps not only filter but also reduce the vector search space thus speeding up the search.\"\n",
      "\n",
      "However, the context doesn't provide detailed technical implementation specifics for large-scale KNN search algorithms or infrastructure setup. The information mainly focuses on RAG pipelines and specific tools rather than comprehensive KNN search methodologies at scale.\n"
     ]
    }
   ],
   "source": [
    "response = await rag(\n",
    "    \"How do I perform a KNN search on a large scale?\", \n",
    "    retrieve_func=retrieve_diverse\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "777b07f6-93a4-4cbf-a8ee-0c5d36422484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/16/25 11:21:01] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> max_tokens is required for Anthropic, setting to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>                     <a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/16/25 11:21:01]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m max_tokens is required for Anthropic, setting to \u001b[1;36m8192\u001b[0m                     \u001b]8;id=303242;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=294993;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\u001b\\\u001b[2m279\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, there are multiple communities mentioned working on different things:\n",
      "\n",
      "1. **Pirates community** - A founder-investor network with 1000 members on WhatsApp and Telegram focused on helping each other succeed, looking to evolve into a product.\n",
      "\n",
      "2. **Bloxd Io community** - A community of builders and creators who connect, share works-in-progress, exchange ideas, and engage in friendly competitions around creative projects.\n",
      "\n",
      "3. **Defense startup community** - People working in defense technology, specifically focusing on SIGINT & RF Spectrum Management solutions and researching market opportunities.\n",
      "\n",
      "4. **Indie tech blog community** - A community for tech bloggers to share what they're working on, post drafts, and comment on other users' posts.\n",
      "\n",
      "5. **JSON Schema organization** - Working on improving JSON Schema through Community Working Meetings and Office Hours.\n",
      "\n",
      "6. **Oasis tech collective** - A community-driven collective building an advocacy flywheel through open-core projects that feed into social advocacy initiatives. They focus on creating open-source versions of closed-source software, mainly working with simple CRUD apps currently.\n",
      "\n",
      "7. **Project communities** - Some are working on projects that need chat platforms for contributors and users to discuss technical matters and coordinate work.\n",
      "\n",
      "The context shows various tech-focused communities working on everything from investment networking to open-source software development to social advocacy through technology.\n"
     ]
    }
   ],
   "source": [
    "response = await rag(\n",
    "    \"What is the community working on?\", \n",
    "    retrieve_func=retrieve_diverse\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d7e404-54ed-435f-acfc-02f593d64bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023-05-30T18:30:35Z Ask HN: Where have you found community outside of work? Asking for myself and those who are looking for what good communities often provide: feeling of connection, purpose, a place to go, etc.',\n",
       " '2024-02-18T07:58:45Z How will you turn a community into a product? I run a tight founder investor network called Pirates. We have 1000 members active on WhatsApp and Telegram. Wonder how to evolve this community into a product. The goal is to help each other succeed. TIA',\n",
       " '2024-02-16T03:48:50Z Show HN: Bloxd Io It&#x27;s a community of passionate builders and creators. Connect with fellow players, share your works-in-progress, exchange ideas, and engage in friendly competitions. Join the conversation on social media using the hashtag #Bloxdio, and be part of a supportive community that celebrates creativity.',\n",
       " '2024-02-18T02:48:57Z Looking for Defense Startup Insights, Communities, Funding, etc. Hi all,<p>I’m currently working within the defense technology space focusing on SIGINT &amp; RF Spectrum Management solutions, researching and gathering market intelligence.<p>I am wanting to focus on the defense startup community to better understand where they may be correlated market opportunities between my lab and new defense startups coming online.<p>My question is; are there defense startup community boards or listing sites that are accessible and specific to defense?<p>Apologies ahead of time if I’m not clear on this but this is the best community I’ve discovered and followed over the past year and I’d value any feedback or guidance to help with my research.<p>Many thanks',\n",
       " '2024-02-01T16:09:05Z Show HN: A Community for Indie Tech Blogs Hey HN! For a while I’ve been trying (unsuccessfully) to find a community for tech bloggers to get together and share what they’re working on, so here’s my attempt at making my own. It’s a completely free website and designed to be super straightforward to use.<p>Functionality wise it’s pretty minimalist right now, with just the ability to register accounts, post drafts, and comment on other user’s posts. Support for more features like tagging post topics, user profiles and more are coming soon!<p>Thanks for checking it out, and I’d love to hear any thoughts from the community.<p>P.S. if you don’t write much yourself but still want to participate, feel free to join! You can give other people feedback without having to post anything of your own.',\n",
       " \"2024-01-10T16:01:24Z Ask HN: Help us improve JSON Schema's Community Working Meetings The JSON Schema organization is looking for honest feedback on how we can make our Community Working Meetings and Office Hours more engaging with the community. We would love to see new recurrent faces in there to help improve JSON Schema.<p>Did you attend an Office Hours or Open Community Working Meeting in the last 12 months?<p>If so, please fill in this 1 minute survey to help us improve!<p>https:&#x2F;&#x2F;docs.google.com&#x2F;forms&#x2F;d&#x2F;e&#x2F;1FAIpQLSenQIBMSQ1LZ2Y5Ar-35FgL9q3KQ9Y3dyHiDwljbjOzrYs3uw&#x2F;viewform<p>You can also find a record of this discussion here: https:&#x2F;&#x2F;github.com&#x2F;json-schema-org&#x2F;community&#x2F;issues&#x2F;566\",\n",
       " '2024-01-27T23:15:13Z Ask HN: How to attain the freedom of Time, Income, and Location Hey HackerNews Community,<p>I&#x27;m at a crossroads in my tech career and could use your collective wisdom. My goal is to strike a balance between time, income, and location freedom. Given the diverse expertise here, I believe this community can offer invaluable insights.<p>Background:\\nHaving accumulated experience in computer science and data, I&#x27;m now eager to explore avenues that provide more flexibility aligning with my lifestyle goals.<p>Seeking Your Expertise:\\nI&#x27;m reaching out to those who&#x27;ve successfully achieved a similar balance. How can one ensure a steady income while enjoying ample personal time and the flexibility to work from anywhere? The objective is to have the freedom to take extended breaks without compromising financial stability.<p>Specific Questions:\\n1. Optimizing Work-Life: What strategies have worked for you in maintaining a healthy work-life balance?\\n2. Stable Income:*How do you secure a consistent income, especially during reduced working hours or time off?\\n3. Remote Work Opportunities:Any tips on finding roles that offer remote work options or flexibility in location?\\n4. Recommended Resources:Are there specific courses, books, or platforms that have guided you on this path?<p>If you&#x27;ve successfully navigated a similar journey or have valuable insights, please share your experiences, tips, or recommended resources. Thank you all for your time and expertise.',\n",
       " '2023-11-02T22:24:02Z Ask HN: Recommended (ideally free) project community chat I&#x27;m currently working on a project that needs a place for contributors and users to chat. Ideally something that is free, at least until the project is large enough to pay for a larger plan.<p>We definitely need a slack-like model to separate topics because it will ideally have both technical discussions around the project as well as a place for moderators and ideally even normal users to talk.<p>Itd be cool™ if it also had something like a forum&#x2F;kb system and in a perfect scenario even a project planning component.<p>I&#x27;ve self-hosted Mattermost in the past and it went really well, but I would sort of like to avoid hosting yet another system if I can avoid it.<p>The project is currently not opensource, but we do plan on doing that at some point and could probably expedite that if it helped get us a free community plan.<p>We are currently using Zulip and while I do like it, its quite foreign to most users and I think thats harming peoples&#x27; ability to get involved. For non-technical users the slack model is already daunting and the Zulip one seems like its just too much.',\n",
       " '2024-01-30T01:46:48Z Show HN: Oasis, the community tech collective building an advocacy flywheel Hey everyone, I wanted to share the project I recently launched called Oasis, which is a community-driven tech collective with the focus of driving social advocacy by creating a self-sustaining flywheel of open-core projects that feeds into our various social advocacy initiatives. The governance is set up much like Open AI, where Oasis is the non-profit that handles the social advocacy and acts as an umbrella for the various OSS projects, and we have a collective structure of contribution with shared ownership so everyone who is working on a project, while it being OSS, gets to share in the financial success.<p>We&#x27;re 100% community driven, and anyone can join the Slack workspace now and contribute to any of the repos, but to actually be an &quot;owner&quot; we do require a $200&#x2F;yr membership fee to help offset operational costs of adding users. All the projects we work on are thoroughly researched for profit potential and technology stack, and currently the angle we&#x27;ve been focusing on a lot of finding closed-source software and essentially ripping their features out into open-core versions. Tangentially, if you have a software you&#x27;d love to see a open-core version of then add a comment in here for sure. We&#x27;re mainly been playing with simple CRUD apps but should the collective grow there&#x27;s potential for other types of projects.',\n",
       " '2023-11-06T19:34:24Z Ask HN: Recommended (ideally free) project community chat I&#x27;m currently working on a project that needs a place for contributors and users to chat. Ideally something that is free, at least until the project is large enough to pay for a larger plan.<p>We definitely need a slack-like model to separate topics because it will ideally have both technical discussions around the project as well as a place for moderators and ideally even normal users to talk.<p>Itd be cool™ if it also had something like a forum&#x2F;kb system and in a perfect scenario even a project planning component.<p>I&#x27;ve self-hosted Mattermost in the past and it went really well, but I would sort of like to avoid hosting yet another system if I can avoid it.<p>The project is currently not opensource, but we do plan on doing that at some point and could probably expedite that if it helped get us a free community plan.<p>We are currently using Zulip and while I do like it, its quite foreign to most users and I think thats harming peoples&#x27; ability to get involved. For non-technical users the slack model is already daunting and the Zulip one seems like its just too much.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_diverse(\"What is the community working on?\", n_docs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2ae3c-c66d-4d3b-9c84-d06b9626989f",
   "metadata": {},
   "source": [
    "## Applying business rules\n",
    "\n",
    "Search does not cover factors such as geographical proximity or recency. We could theoretically apply payload filters to restrict data coming from last week, month, or year, but it's not an ideal solution if we want to express a preference, not a hard limit. If we want to combine relevance with some additional criteria, we need to recalculate the scores based on the scores as returned by individual methods, and the other factors we want to consider. Score boosting is a mechanism providing a way to achieve exactly this.\n",
    "\n",
    "HackerNews provides a `time` attribute we converted to a proper `datetime` at the very beginning. Let's try to use if for recency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24321594-5308-4e5e-9c31-385cb3036a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "def retrieve_recent(q: str, n_docs: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the provided query\n",
    "    with BM25 and dense retrieval + recency.\n",
    "    \"\"\"\n",
    "    result = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=BM25_MODEL_NAME,\n",
    "                ),\n",
    "                using=BM25_VECTOR_NAME,\n",
    "                # Ten times more than expected\n",
    "                limit=(n_docs * 10),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=MODEL_NAME,\n",
    "                ),\n",
    "                using=VECTOR_NAME,\n",
    "                # Ten times more than expected\n",
    "                limit=(n_docs * 10),\n",
    "            ),\n",
    "        ],\n",
    "        # Score boosting\n",
    "        query=models.FormulaQuery(\n",
    "            formula=models.MultExpression(\n",
    "                mult=[\n",
    "                    \"$score\",\n",
    "                    models.ExpDecayExpression(\n",
    "                        exp_decay=models.DecayParamsExpression(\n",
    "                            x=models.DatetimeKeyExpression(\n",
    "                                datetime_key=\"datetime\" # payload key \n",
    "                            ),\n",
    "                            # Current datetime in \"2025-09-25T00:00:00Z format\n",
    "                            target=models.DatetimeExpression(\n",
    "                                datetime=datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                            ),\n",
    "                            scale=86400 * 365, # 1 day in seconds * 365\n",
    "                            # If item's \"datetime\" is more than 1 year apart from \n",
    "                            # the current datetime, relevance score is less than 0.5\n",
    "                            midpoint=0.5\n",
    "                        )\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        # Five times more than expected too\n",
    "        limit=n_docs,\n",
    "    )\n",
    "    docs = [\n",
    "        f\"{point.payload['datetime']} {point.payload['title']} {point.payload['text']}\"\n",
    "        for point in result.points\n",
    "    ]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5542664c-28fe-470d-a6e8-169365522986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2025-09-11T09:43:57Z When Startups Ask for Free Security Work A few weeks ago, I explored [redacted], a YC-backed AI backend platform. Like many security researchers, I tend to poke at new tools to see how they handle common attack vectors.<p>It didn’t take long to find issues, both in security and user experience.<p>## The Vulnerabilities<p>*Authorization Flaw*: [redacted] limits free users to 3 items, with a paywall for more. But their API doesn’t enforce this. Anyone can bypass the frontend and call the API directly.<p>This classic flaw means free users can generate unlimited content, paid tiers lose value, and the business model collapses.<p>*UX Problems*: The platform also has confusing navigation, inconsistent design, poor hierarchy, clunky workflows, and unclear onboarding. When the product experience feels this raw, security flaws are just another sign of neglect.<p>## The Response<p>I asked in their community channel about their disclosure process. The founder replied:<p>“hi [name], i just saw your message on the general channel. right now, we are not hiring, but people are helping improving the platform and this is a good test for the future, when we will hire people. if you want to contribute, feel free to report bugs or security issues to us. if security related, it&#x27;s best on private dms rather than on general channel”<p>Translation: <i>Please do free security work for us. Maybe we’ll hire you someday.</i><p>## Why I Didn’t Disclose<p>I withheld details because:  \\n- No bug bounty or acknowledgment system  \\n- Security research framed as &quot;free testing&quot;  \\n- Vague promise of future consideration, not present compensation  \\n- No disclosure policy or timeline  \\n- Overall lack of professionalism<p>Finding and responsibly reporting vulnerabilities takes skill. Expecting researchers to do it for free, especially from a funded startup, is unacceptable.<p>## The Broader Problem<p>This reflects a larger startup issue: wanting community help without paying for it. Companies routinely ask for unpaid QA, security audits, bug reports, and UX feedback while raising millions.<p>## What Good Companies Do<p>The best companies have:  \\n- Clear disclosure policies with defined timelines  \\n- Bug bounty programs (even small ones show respect)  \\n- Professional communication with researchers  \\n- Public acknowledgment for responsible disclosure<p>It doesn’t take much. Even a $10 gift card and a thank-you matter.<p>## Current Status<p>A month later, the vulnerability is still unfixed, and UX remains rough.<p>For users, this means inaccurate usage tracking, broken economics, possible deeper issues, and ongoing frustration. For the company, it reveals a culture where security, UX, and respect are afterthoughts.<p>## Lessons for Founders<p>*Security basics*:  \\n- Enforce all limits server-side. Never trust the frontend.  \\n- Publish a simple disclosure policy.  \\n- Respect researchers, we’re trying to help.<p>*Cultural basics*:  \\n- Don’t ask for free labor.  \\n- Treat feedback as valuable, not free QA.  \\n- Remember that first impressions last.<p>The security community wants to help, but not at the cost of undervaluing expertise.<p>Build secure products. Create intuitive experiences. Respect those who help you improve. Security debt compounds quickly, but UX debt kills adoption even faster.<p>---<p>Have you had similar experiences with AI startups expecting free security work? How do you handle companies that dismiss security?',\n",
       " '2024-06-25T11:47:07Z Show HN: Lambda – An Open-Source Privacy-Focused Social Media App Hi HN community!<p>I’m excited to introduce Lambda, a project I&#x27;ve been working on. Lambda is the world&#x27;s first open-source social media app designed to prioritize your privacy and well-being. It&#x27;s still in its early stages, but I&#x27;m eager to share it with you and get your feedback.<p>What is Lambda?<p>Lambda is an open-source social media app that addresses privacy concerns and reduces social media addiction. Here&#x27;s what makes Lambda unique:<p>- Privacy First: Lambda does not collect personal information beyond your email address for account creation. Your data is yours alone.\\n- Organic Feed: No AI-generated feeds or targeted advertisements. You only see posts from users you follow.\\n- Open Source: Built-in public, with community feedback and contributions highly encouraged.<p>Tech Stack<p>Frontend: Next.js with React\\n Backend: Supabase (BaaS)\\n Hosting: Vercel\\n Language: TypeScript<p>What&#x27;s Next?<p>Currently, Lambda is a basic version with text-only posts. Here are some things I’m working on:<p>Adding support for images and videos\\n Reducing latency\\n Enhancing the overall user experience\\n Try it out!<p>You can check out Lambda and create an account here. Feel free to explore, and I’d love to hear your thoughts and suggestions.<p>GitHub Repository<p>If you&#x27;re interested in contributing or just curious about the code, you can find the repository here. A star on GitHub would be greatly appreciated!<p>Feedback<p>I’m around to discuss and answer any questions you might have. Your feedback is invaluable, and I&#x27;m looking forward to improving Lambda with the help of the HN community.<p>Thanks for taking the time to check out Lambda!<p>Best regards,\\nEzpieCo(not my real name)',\n",
       " '2024-06-24T10:35:18Z Ask HN: Supabase vs. Neon Database: Which One Should I Choose? I wonder if HN could share their favorite serverless Postgres database?<p>I&#x27;m currently evaluating different database solutions for a SaaS I&#x27;m working on, and I&#x27;ve narrowed it down to Supabase and Neon Database. I&#x27;ve done some initial research, but I&#x27;m looking for more insights from the community.<p>Here are a few specifics about my project:<p>* Scale: Anticipating moderate to high traffic\\n* Tech Stack: very minimal I can go for a web app:- JavaScript, TypeScript using NextJS, ReactJS- TailwindCSS, RadixUI for UI- Deploy on Vercel \\n* Key Requirements: Real-time capabilities, ease of use, performance, cost-efficiency, and good support&#x2F;docs.<p>Questions:<p>1. Performance and Scalability: How do these two compare in terms of handling large-scale applications? Any real-world experiences would be great.\\n2. Ease of Use: Which one has a more developer-friendly interface and better docs?\\n3. Real-time Features: How do their real-time features stack up against each other?\\n4. Community and Support: How active and helpful are their communities and support teams?\\n5. Cost: Any insights on the cost-effectiveness of each, especially for scaling applications?<p>I&#x27;m leaning towards one but would love to hear your thoughts and experiences.',\n",
       " \"2024-06-23T04:09:57Z My New App for Parents to Buy and Sell Gently Used Baby and Kids' Gear Hello there - I’m built and launched a new app called Growr - it&#x27;s a marketplace for baby &amp; kids stuff.<p>As a parent myself, I’ve experienced firsthand how quickly our little ones outgrow their clothes, toys, and gear. It’s tough on the wallet and contributes to unnecessary waste. That’s why I created Growr, a marketplace specifically designed for buying and selling gently used baby and kids&#x27; items. My goal is to make parenting more affordable and sustainable for everyone.<p>The way it works is simple - as a seller, you list your baby&#x27;s or kid&#x27;s item and wait for the buyer to contact you. As a buyer, you look for what you want and start chatting with the seller. It&#x27;s all local based, which will help with community building as well.<p>We&#x27;re working on building various functionalities such as rating system, payments, and options to deliver so that we can support the communities better.<p>You can find the link here: iPhone: https:&#x2F;&#x2F;apps.apple.com&#x2F;be&#x2F;app&#x2F;growr&#x2F;id6465306158 Android: https:&#x2F;&#x2F;play.google.com&#x2F;store&#x2F;apps&#x2F;details?id=com.modoo.mothings<p>Check them out! If you have any feedback, please feel free to reach out. Thanks!\",\n",
       " '2024-06-27T09:55:33Z Show HN: Lambda – The first-ever open-source privacy based social media app Hi HN community!<p>NOTE: This is a repost due to missing of links<p>I’m excited to introduce Lambda, a project I&#x27;ve been working on. Lambda is the world&#x27;s first open-source social media app designed to prioritize your privacy and well-being. It&#x27;s still in its early stages, but I&#x27;m eager to share it with you and get your feedback.<p>What is Lambda?<p>Lambda is an open-source social media app that addresses privacy concerns and reduces social media addiction. Here&#x27;s what makes Lambda unique:<p>- Privacy First: Lambda does not collect personal information beyond your email address for account creation. Your data is yours alone.<p>- Organic Feed: No AI-generated feeds or targeted advertisements. You only see posts from users you follow.<p>- Open Source: Built-in public, with community feedback and contributions highly encouraged.<p>What&#x27;s Next?<p>Currently, Lambda is a basic version with text-only posts. Here are some things I’m working on:<p>- Adding support for images and videos<p>- Reducing latency<p>- Enhancing the overall user experience<p>You can check out Lambda and create an account here[<a href=\"https:&#x2F;&#x2F;lambda-official.vercel.app\" rel=\"nofollow\">https:&#x2F;&#x2F;lambda-official.vercel.app</a>]. Feel free to explore, and I’d love to hear your thoughts and suggestions here[<a href=\"https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official&#x2F;discussions&#x2F;categories&#x2F;feedback\">https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official&#x2F;discussions&#x2F;catego...</a>]<p>GitHub Repository<p>If you&#x27;re interested in contributing or just curious about the code, you can find the repository here[<a href=\"https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official\">https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official</a>]. A star on GitHub would be... private... I am not a comedian.<p>Feedback<p>I’m around to discuss and answer any questions you might have, you can always jump over to GitHub discussion[<a href=\"https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official&#x2F;discussions&#x2F;categories&#x2F;feedback\">https:&#x2F;&#x2F;github.com&#x2F;ezpie1&#x2F;lambda-official&#x2F;discussions&#x2F;catego...</a>] and drop feedback there. Your feedback is extremely valuable, and I&#x27;m looking forward to improving Lambda with the help of the HN community.<p>Thanks for taking the time to check out Lambda!<p>Best regards, EzpieCo(not my real name)',\n",
       " '2024-06-26T18:18:46Z Show HN: A VR-chat App for online gatherings Hey HN,<p>I&#x27;ve been working on a VR-chat app, something like a 3D version of Zoom, and I&#x27;d love to get your feedback.<p>I built the app using React and BabylonJS. It uses DailyCo for WebRTC, enabling real-time video and audio communication.<p>Features:\\nUsers can create virtual rooms to hang out with their friends.\\nCustom spatial audio allows you to converse with people in the room, even with other conversations happening nearby.\\nMinimalist design for quick loading and compatibility with slower systems.<p>Why I built it:\\nThe goal is to bring distributed remote communities closer together by simulating real-life social gatherings, especially for those who can&#x27;t meet up in person.<p>Current state:\\nIt&#x27;s a basic prototype right now, and I&#x27;m looking to gauge interest and gather feedback from the community.<p>Try it out:\\nYou can hop into a sample room here: <a href=\"https:&#x2F;&#x2F;digital-den.onrender.com&#x2F;room?roomId=universal-hangout\" rel=\"nofollow\">https:&#x2F;&#x2F;digital-den.onrender.com&#x2F;room?roomId=universal-hango...</a> to get a feel for the app and the spatial audio in action. I&#x27;ll be in the room to chat and answer any questions you might have.<p>Looking forward to hearing your thoughts and suggestions!<p>Thanks,\\nOmar S.',\n",
       " '2024-06-24T05:56:12Z Show HN: We are building your AI co-founder to help your run your startup Hey HN,<p>I quit my 9 to 5 to join an accelerator. Let&#x27;s say things didn&#x27;t work out there. After launching my fourth startup and failing miserably again I decided to work on Frederick AI.<p>I realised a lot of the early stage processes from idea to startup are the same and we can use AI to automate a lot of it from the way we come up with an idea to how we run startups.<p>Frederick AI is a set of tools for early stage founders we collect Market Data 24&#x2F;7 to detect consumer, business and government problems for other startup founders to go and solve.<p>We then create a business plan and a landing page to help you get feedback in less than a minute.<p>We are super early still would love to get some feedback from the community!. Let us know if we can build anything for you.',\n",
       " '2024-06-18T13:08:15Z Show HN: Radius – A Meetup.com alternative Hey everyone! I&#x27;m introducing Radius - a project I&#x27;ve been working on for too long! It&#x27;s an early stage and pretty minimal (which, according to YC means I launched early enough) alternative to Meetup.com, built using Ruby on Rails. It&#x27;s a platform for creating thriving communities and discovering events around you.<p>What can you do on Radius?<p>- Want to create a group, post events and gather RSVPs? You&#x27;re covered!<p>- Want event discovery? Coming soon™!<p>I&#x27;m a software engineer based in the UK. My first attempt to make this failed spectacularly when I hired a budget dev years ago to &quot;build an MVP&quot; when I had next to no knowledge of software development. So naturally, I changed my career and learned how to build it myself.<p>I wanted to build something that made it easy to find out what was happening around you. We have all these platforms focused on ticketing, meetups, and other event types - but they&#x27;re all niche enough that they each only list a fragment of what&#x27;s going on around us. Then you have another subset of groups which host their own website&#x2F;mailing list and may only advertise an event on -insert social network- and you never know about it until it&#x27;s too late.<p>The issue I have with existing platforms:<p>- Meetup excludes too many groups by not offering a free tier for smaller&#x2F;non-profit groups which make up for a huge number of small communities. So many groups just end up dying because one person has to pay the fees. Then there&#x27;s the fact that their search experience is just terrible. FWIW, I also think they have a marketing issue with the name Meetup.<p>- Eventbrite does ticketing pretty well, but completely failed to develop the group&#x2F;community aspect and doesn&#x27;t seem to have put much emphasis on the discovery of events either. They, like Meetup, only attract a certain subset of groups&#x2F;events as well.<p>So, it feels like there&#x27;s an opportunity to fill the gap with something that focuses on a wider range of events&#x2F;groups and emphasises discovery and community. There&#x27;s so much activity happening around us in the real world - and that&#x27;s what I&#x27;d eventually like Radius to capture.<p>I&#x27;m aware that the discovery app category falls into the list of &quot;YC honeypot ideas&quot; but in the time that I&#x27;ve cared about this, nobody has built the thing I wanted to exist, damn it (Maybe that&#x27;s a sign NOT to build it..).<p>At best, people might find this useful and at worst, it&#x27;s been a fantastic learning experience.<p>--<p>Feedback -<p>There are a bunch of groups using it for events at the moment, and they&#x27;ve given great feedback to date. I haven&#x27;t advertised it much though, so this is my attempt at gathering the next wave of feedback. Feel free to:<p>- Try it out: See if Radius works for your groups and events.<p>- Give feedback: Let me know what you think and how we can improve.<p>- Request features: Tell me what features would make Radius even better.<p>Thanks!<p>Link:- <a href=\"https:&#x2F;&#x2F;www.radius.to&#x2F;\" rel=\"nofollow\">https:&#x2F;&#x2F;www.radius.to&#x2F;</a><p>Example group:- <a href=\"https:&#x2F;&#x2F;www.radius.to&#x2F;groups&#x2F;toronto-ruby\" rel=\"nofollow\">https:&#x2F;&#x2F;www.radius.to&#x2F;groups&#x2F;toronto-ruby</a><p>Example event:- <a href=\"https:&#x2F;&#x2F;www.radius.to&#x2F;groups&#x2F;toronto-ruby&#x2F;events&#x2F;s1tczn2usqf5\" rel=\"nofollow\">https:&#x2F;&#x2F;www.radius.to&#x2F;groups&#x2F;toronto-ruby&#x2F;events&#x2F;s1tczn2usqf...</a>',\n",
       " \"2024-01-10T16:01:24Z Ask HN: Help us improve JSON Schema's Community Working Meetings The JSON Schema organization is looking for honest feedback on how we can make our Community Working Meetings and Office Hours more engaging with the community. We would love to see new recurrent faces in there to help improve JSON Schema.<p>Did you attend an Office Hours or Open Community Working Meeting in the last 12 months?<p>If so, please fill in this 1 minute survey to help us improve!<p>https:&#x2F;&#x2F;docs.google.com&#x2F;forms&#x2F;d&#x2F;e&#x2F;1FAIpQLSenQIBMSQ1LZ2Y5Ar-35FgL9q3KQ9Y3dyHiDwljbjOzrYs3uw&#x2F;viewform<p>You can also find a record of this discussion here: https:&#x2F;&#x2F;github.com&#x2F;json-schema-org&#x2F;community&#x2F;issues&#x2F;566\",\n",
       " '2024-02-18T02:48:57Z Looking for Defense Startup Insights, Communities, Funding, etc. Hi all,<p>I’m currently working within the defense technology space focusing on SIGINT &amp; RF Spectrum Management solutions, researching and gathering market intelligence.<p>I am wanting to focus on the defense startup community to better understand where they may be correlated market opportunities between my lab and new defense startups coming online.<p>My question is; are there defense startup community boards or listing sites that are accessible and specific to defense?<p>Apologies ahead of time if I’m not clear on this but this is the best community I’ve discovered and followed over the past year and I’d value any feedback or guidance to help with my research.<p>Many thanks']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_recent(\"What is the community working on?\", n_docs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98359de9-9928-45b5-aece-20471fb56dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/16/25 11:21:44] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> max_tokens is required for Anthropic, setting to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>                     <a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/16/25 11:21:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m max_tokens is required for Anthropic, setting to \u001b[1;36m8192\u001b[0m                     \u001b]8;id=434759;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=877420;file:///home/kacper/Projects/Qdrant/workshop-improving-r-in-rag/.venv/lib/python3.12/site-packages/any_llm/providers/anthropic/utils.py#279\u001b\\\u001b[2m279\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, I can see several different communities working on various projects:\n",
      "\n",
      "1. **JSON Schema Community** - They are working on improving JSON Schema and making their Community Working Meetings and Office Hours more engaging. They're seeking feedback to attract new recurring participants to help improve JSON Schema.\n",
      "\n",
      "2. **Defense Startup Community** - Someone is researching this community to understand market opportunities in defense technology, specifically focusing on SIGINT & RF Spectrum Management solutions.\n",
      "\n",
      "3. **Various Individual Startup Communities** working on:\n",
      "   - **Lambda** - An open-source, privacy-focused social media app\n",
      "   - **Growr** - A marketplace app for buying and selling used baby and kids' items\n",
      "   - **Frederick AI** - AI tools for early-stage startup founders, including market data collection and business plan generation\n",
      "   - **Radius** - A Meetup.com alternative for creating communities and discovering events\n",
      "   - **A VR-chat app** - A 3D version of Zoom for online gatherings\n",
      "   - **Database evaluation** - Community discussing serverless Postgres solutions (Supabase vs. Neon Database)\n",
      "\n",
      "The context shows multiple independent communities and projects rather than one unified community working on a single initiative. Each appears to be working on their respective products and seeking feedback or engagement from the broader tech community.\n"
     ]
    }
   ],
   "source": [
    "response = await rag(\n",
    "    \"What is the community working on?\", \n",
    "    retrieve_func=retrieve_recent\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b5a92-7c53-4740-9a68-e6369549ffc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
