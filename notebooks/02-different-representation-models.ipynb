{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa31f560-d5ab-4bbd-84e0-605c635f0deb",
   "metadata": {},
   "source": [
    "# Testing different representation methods\n",
    "\n",
    "Dense retrieval is easy to start with, but it does not provide the most accurate answers in all the cases. Sometimes, we need exact keyword matching and in that cases sparse vectors, such as BM25 might be more appropriate. They definitely excel at proper names detection, and we may need that to search over our datasets, with specific company constraints in mind. Let's add another representation method and build hybrid search using both of them."
   ]
  },
  {
   "cell_type": "code",
   "id": "277e8b4c-7178-48c9-b547-b72cc058d059",
   "metadata": {},
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "69e4c55f-ce6a-4e22-b499-424293579e7a",
   "metadata": {},
   "source": [
    "## Setting up another Qdrant collection for multiple vectors per point\n",
    "\n",
    "If we want to use different search methods, we need to store multiple vectors per point in one collection. It's easier that way, as multi-stage retrieval pipelines might be launched in a single API call."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae288b6c-10de-40fd-81c9-f421bbf0ce63",
   "metadata": {},
   "source": [
    "# See: https://qdrant.github.io/fastembed/examples/Supported_Models/#supported-text-embedding-models\n",
    "COLLECTION_NAME = \"hackernews-hybrid-rag\"\n",
    "\n",
    "# Dense retrieval\n",
    "MODEL_NAME = \"BAAI/bge-small-en-v1.5\"\n",
    "VECTOR_SIZE = 384\n",
    "VECTOR_NAME = \"bge-small-en-v1.5\"\n",
    "\n",
    "# Sparse model\n",
    "BM25_MODEL_NAME = \"Qdrant/bm25\"\n",
    "BM25_VECTOR_NAME = \"bm25\"\n",
    "\n",
    "# Token-level representations\n",
    "MUTLIVECTOR_MODEL_NAME = \"colbert-ir/colbertv2.0\"\n",
    "MULTIVECTOR_SIZE = 128\n",
    "MULTIVECTOR_NAME = \"colbertv2.0\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36076f5e-37f0-4433-a553-31ffbf550b44",
   "metadata": {},
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "import os\n",
    "\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd39448a-c71b-40d5-9bde-e8d69c470328",
   "metadata": {},
   "source": [
    "client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config={\n",
    "        VECTOR_NAME: models.VectorParams(\n",
    "            size=VECTOR_SIZE,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "        MULTIVECTOR_NAME: models.VectorParams(\n",
    "            size=MULTIVECTOR_SIZE,\n",
    "            distance=models.Distance.DOT,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            # Disable HNSW for reranking\n",
    "            hnsw_config=models.HnswConfigDiff(m=0),\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        BM25_VECTOR_NAME: models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        ),\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5473c79-a010-4ad5-94b0-ced242ec5217",
   "metadata": {},
   "source": [
    "## Migrating to multiple vectors\n",
    "\n",
    "There is no need to recreate the previously created dense embeddings, as we can migrate them from the previous collection and avoid recomputations. In the meantime we'll still create sparse and multi-vector representations. Also, since we agreed we need more context, we don't really need to store the points without more detailed text description of a submission, so let's filter them out."
   ]
  },
  {
   "cell_type": "code",
   "id": "69ca4905-40b0-46be-8b7e-6c70efce358e",
   "metadata": {},
   "source": [
    "OLD_COLLECTION_NAME = \"hackernews-rag\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "212cede3-1029-48f7-a33b-e7516e779ae8",
   "metadata": {},
   "source": [
    "last_offset = None\n",
    "while True:\n",
    "    # Get a batch of records\n",
    "    records, last_offset = client.scroll(\n",
    "        collection_name=OLD_COLLECTION_NAME, \n",
    "        scroll_filter=models.Filter(\n",
    "            must_not=[\n",
    "                # Lack of field\n",
    "                models.IsEmptyCondition(\n",
    "                    is_empty=models.PayloadField(key=\"text\"),\n",
    "                ),\n",
    "                # Field set to null value\n",
    "                models.IsNullCondition(\n",
    "                    is_null=models.PayloadField(key=\"text\"),\n",
    "                ),\n",
    "                # Field set to an empty string\n",
    "                models.FieldCondition(\n",
    "                    key=\"text\",\n",
    "                    match=models.MatchValue(value=\"\"),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "        offset=last_offset,\n",
    "        with_payload=True,\n",
    "        with_vectors=True,\n",
    "        limit=10,\n",
    "    )\n",
    "\n",
    "    # Migrate them to a new collection\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=record.id,\n",
    "                vector={\n",
    "                    # Copy the dense embedding directly\n",
    "                    VECTOR_NAME: record.vector[VECTOR_NAME],\n",
    "                    # Calculate BM25 embedding\n",
    "                    BM25_VECTOR_NAME: models.Document(\n",
    "                        text=f\"{record.payload['title']} {record.payload['text']}\",\n",
    "                        model=BM25_MODEL_NAME,\n",
    "                    ),\n",
    "                    # Calculate ColBERT embeddings as well\n",
    "                    MULTIVECTOR_NAME: models.Document(\n",
    "                        text=f\"{record.payload['title']} {record.payload['text']}\",\n",
    "                        model=MUTLIVECTOR_MODEL_NAME,\n",
    "                    ),\n",
    "                },\n",
    "                payload=record.payload,\n",
    "            )\n",
    "            for record in records\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Stop when the last batch has been already processed\n",
    "    if last_offset is None:\n",
    "        break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98cd9a15-e784-4c37-a65a-f24cdb671613",
   "metadata": {},
   "source": [
    "client.recover_snapshot(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    # Please do not modify the URL below\n",
    "    location=\"https://storage.googleapis.com/tutorials-snapshots-bucket/workshop-improving-r-in-rag/hackernews-hybrid-rag.snapshot\",\n",
    "    wait=False, # Loading a snapshot may take some time, so let's avoid a timeout\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce9cdc01-da71-40ac-af3a-ea1ba72b601a",
   "metadata": {},
   "source": [
    "## Experimenting with Hybrid Search\n",
    "\n",
    "Our previous attempts to use dense retrieval to find some Qdrant-specific data weren't succesful. Let's try to build a better retriever that will use keyword-based search retrieval and dense reranking, so it hopefully capture more nuances."
   ]
  },
  {
   "cell_type": "code",
   "id": "69a57a86-eafd-4038-a013-d5c11ea83301",
   "metadata": {},
   "source": [
    "def retrieve_dual(q: str, n_docs: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the provided query\n",
    "    with BM25 retrieval and dense reranking.\n",
    "    \"\"\"\n",
    "    result = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=BM25_MODEL_NAME,\n",
    "                ),\n",
    "                using=BM25_VECTOR_NAME,\n",
    "                # Prefetch ten times more!\n",
    "                limit=(n_docs * 10)\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=q,\n",
    "            model=MODEL_NAME,\n",
    "        ),\n",
    "        using=VECTOR_NAME,\n",
    "        limit=n_docs,\n",
    "    )\n",
    "    docs = [\n",
    "        f\"{point.payload['title']} {point.payload['text']}\"\n",
    "        for point in result.points\n",
    "    ]\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43ef142c-4ddb-4a1a-baf6-6fdb649f5dff",
   "metadata": {},
   "source": [
    "retrieve_dual(\"What does Qdrant do?\", n_docs=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "191de14d-70b3-43b6-8efa-07d777e2ac96",
   "metadata": {},
   "source": [
    "from any_llm import acompletion\n",
    "from typing import Callable\n",
    "\n",
    "RetieverFunc = Callable[[str, int], list[str]]\n",
    "\n",
    "LLM_NAME = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "async def rag(q: str, retrieve_func: RetieverFunc, *, n_docs: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Run single-turn RAG on a given input query.\n",
    "    Return just the model response.\n",
    "    \"\"\"\n",
    "    docs = retrieve_func(q, n_docs)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Please provide a response to my question based only \" +\n",
    "                \"on the provided context and only it. If it doesn't \" +\n",
    "                \"contain any helpful information, please let me know \" +\n",
    "                \"and admit you cannot produce relevant answer.\\n\" +\n",
    "                f\"<context>{'\\n'.join(docs)}</context>\\n\" +\n",
    "                f\"<question>{q}</question>\"\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    response = await acompletion(\n",
    "        provider=os.environ.get(\"LLM_PROVIDER\"),\n",
    "        model=LLM_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "455d4ec8-dcc8-4c2d-a8e0-cb95b6ce597b",
   "metadata": {},
   "source": [
    "response = await rag(\n",
    "    \"What does Qdrant do?\", \n",
    "    retrieve_func=retrieve_dual\n",
    ")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6cb7968e-e57e-4827-b79c-80ead2811117",
   "metadata": {},
   "source": [
    "retrieve_dual(\"How do I perform a KNN search on a large scale?\", n_docs=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "01af463d-66c8-495a-b472-f75629457c61",
   "metadata": {},
   "source": [
    "### More sophisticated reranking\n",
    "\n",
    "Sparse retrieval and dense reranking might be a useful strategy, but it cannot support all the possible search queries. If we cannot capture a particular semantic match using sparse vectors, then dense reranking won't even see it, so it'll never get retrieved. That's why it pretty common to use both methods for prefetching, and something else for reranking, so we can have the best of both worlds.\n",
    "\n",
    "In the simplest case, we can run both prefetches and combine the results with fusion based on the ranks as returned by the individual methods."
   ]
  },
  {
   "cell_type": "code",
   "id": "2dabcf0f-abb2-4edb-86b1-b5c7ff61cc64",
   "metadata": {},
   "source": [
    "def retrieve_fusion(q: str, n_docs: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the provided query\n",
    "    with BM25 and dense retrieval + fusion to merge them.\n",
    "    \"\"\"\n",
    "    result = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=BM25_MODEL_NAME,\n",
    "                ),\n",
    "                using=BM25_VECTOR_NAME,\n",
    "                limit=n_docs,\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=MODEL_NAME,\n",
    "                ),\n",
    "                using=VECTOR_NAME,\n",
    "                limit=n_docs,\n",
    "            ),\n",
    "        ],\n",
    "        # Reciprocal Rank Fusion works on the rankings\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        limit=n_docs,\n",
    "    )\n",
    "    docs = [\n",
    "        f\"{point.payload['title']} {point.payload['text']}\"\n",
    "        for point in result.points\n",
    "    ]\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93f0663a-65e8-4380-9467-bfdfe774c1ef",
   "metadata": {},
   "source": [
    "retrieve_fusion(\"How do I perform a KNN search on a large scale?\", n_docs=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3a69b489-f3e1-44c0-b07e-7cc969ad4b95",
   "metadata": {},
   "source": [
    "response = await rag(\n",
    "    \"How do I perform a KNN search on a large scale?\", \n",
    "    retrieve_func=retrieve_fusion\n",
    ")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb48fc9f-bd1c-4ddb-8dbc-f53d439561d8",
   "metadata": {},
   "source": [
    "More complex problems may require running better rerankers to capture the data nuances. That's why we also created ColBERT embeddings, and it's finally time to test them."
   ]
  },
  {
   "cell_type": "code",
   "id": "d20abccd-e8d4-4c00-a3c4-12911be37b81",
   "metadata": {},
   "source": [
    "def retrieve_colbert_reranking(q: str, n_docs: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Retrieve documents based on the provided query\n",
    "    with BM25 and dense retrieval + ColBERT to merge them.\n",
    "    \"\"\"\n",
    "    result = client.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=BM25_MODEL_NAME,\n",
    "                ),\n",
    "                using=BM25_VECTOR_NAME,\n",
    "                limit=n_docs,\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=q,\n",
    "                    model=MODEL_NAME,\n",
    "                ),\n",
    "                using=VECTOR_NAME,\n",
    "                limit=n_docs,\n",
    "            ),\n",
    "        ],\n",
    "        # Reranking with ColBERT embeddings\n",
    "        query=models.Document(\n",
    "            text=q,\n",
    "            model=MUTLIVECTOR_MODEL_NAME,\n",
    "        ),\n",
    "        using=MULTIVECTOR_NAME,\n",
    "        limit=n_docs,\n",
    "    )\n",
    "    docs = [\n",
    "        f\"{point.payload['title']} {point.payload['text']}\"\n",
    "        for point in result.points\n",
    "    ]\n",
    "    return docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5e0c4cd6-4fe6-4595-9e6b-50ced9ddac17",
   "metadata": {},
   "source": [
    "response = await rag(\n",
    "    \"How do I perform a KNN search on a large scale?\", \n",
    "    retrieve_func=retrieve_colbert_reranking\n",
    ")\n",
    "print(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c8cb304-231a-44f0-a182-5a2d8f416e59",
   "metadata": {},
   "source": [
    "retrieve_colbert_reranking(\"How do I perform a KNN search on a large scale?\", n_docs=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f63535bc-722d-4f13-a4ac-08eadead3cf3",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
